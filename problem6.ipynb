{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69f6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ab765",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9692aad",
   "metadata": {},
   "source": [
    "#### $$L = \\sum\\limits_{i = 1}^l (y_i - \\check{y})^2 \\rightarrow \\min\\limits_{\\check{y}}$$\n",
    "$$\\frac{\\partial L}{\\partial\\check{y}} = -\\sum\\limits_{i = 1}^l 2(y_i - \\check{y}) = 0 \\Rightarrow \\check{y} = \\frac{1}{l}\\sum\\limits_{i = 1}^{l} y_i = \\overline{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a7ef01",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c55ee8",
   "metadata": {},
   "source": [
    "#### $\\check{y} = \\check{w}x + \\check{b}$ - прямая, построенная по МНК, где параметры $\\check{w}, \\check{b}$ находится из минимизации функции $L = \\sum\\limits_{i = 1}^{l}(y_i - wx_i - b)^2$:\n",
    "\n",
    " \\begin{cases}\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial w} = 2\\sum\\limits_{i = 1}^{l}(y_i - wx_i - b)(-x_i) = 0 \\\\\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial b} = 2\\sum\\limits_{i = 1}^{l}(y_i - wx_i - b)(-1) = 0\n",
    " \\end{cases}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9319b58",
   "metadata": {},
   "source": [
    "#### Из второго уравнения, деля на $l$, сразу получаем: $\\overline{y} = \\check{w}\\overline{x} + \\check{b}$. Обобщим на случай многомерной регрессии:\n",
    "\n",
    "$\\check{y} = X\\check{w}$, где $X$ - матрица объект-признак (свободный член можно сразу учесть). Воспльзуемся сразу ответом (его легко получить из тензорной нотации): $\\check{w} = (X_0^{T}X_0)^{-1}X_0^{T}y_0$, где нижний индекс \"0\" означает исходную серию измерений. Подставим в качестве $X$ начальную матрицу $X_0$ и домножим слева на $X_0^T$: $X_0^T \\check{y_0} = (X_0^T X_0)  (X_0^{T}X_0)^{-1}X_0^{T}y_0 = X_0^T y_0 \\Rightarrow X_0^T(\\check{y_0} - y_0) = 0$. Считая признаки независимами, то есть столбцы матрицы $X_0$ независимыми, получим: $\\check{y_0} = y_0$. Таким образом, гиперплоскость, построенная по МНК, пересекается с исходной гиперплоскостью (по серии измерений)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b29aa4",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2a9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b1cf64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
